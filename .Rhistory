key=key+1
if (key==1){
out_quasi=ddloglik_schoenfeld(n=N,delta,z=z,beta=constant_beta,B_spline=bs8, knot=K_set[i])
H=out_quasi$GVG
g_pre=-matrix(out_quasi$GR_test,ncol=1)
d_pre=matrix(t(theta_quasi), ncol=1)
dist=matrix(solve(H)%*%g_pre, nrow=p, byrow=TRUE)
theta_quasi=theta_quasi-dist
out_quasi=ddloglik_schoenfeld_bs_t_quasi_L1(n=N,delta=delta,z=z,B_spline=bs8,  theta=theta_quasi,p,K_set[i])
g=matrix(out_quasi$L1,ncol=1)-g_pre
d=matrix(t(theta_quasi), ncol=1)-d_pre
b=as.vector(1/(t(g)%*%d))
c=as.vector(-1/(t(d)%*%H%*%d))
H=H+b*g%*%t(g)+c*H%*%d%*%t(d)%*%H
g_pre=matrix(out_quasi$L1,ncol=1)
d_pre=matrix(t(theta_quasi), ncol=1)
}
if (key>1){
dist=matrix(solve(H)%*%matrix(out_quasi$L1,ncol=1), nrow=p, byrow=TRUE)
theta_quasi=theta_quasi-dist
out_quasi=ddloglik_schoenfeld_bs_t_quasi_L1(n=N,delta=delta,z=z,B_spline=bs8,  theta=theta_quasi,p,K_set[i])
g=matrix(out_quasi$L1,ncol=1)-g_pre
d=matrix(t(theta_quasi), ncol=1)-d_pre
g_pre=matrix(out_quasi$L1,ncol=1)
d_pre=matrix(t(theta_quasi), ncol=1)
b=as.vector(1/(t(g)%*%d))
c=as.vector(-1/(t(d)%*%H%*%d))
H=H+b*g%*%t(g)+c*H%*%d%*%t(d)%*%H
}
if ( is.na(max(abs(dist))<tol) )
{
is.error=T
break
}
r_temp=suppressWarnings(try(solve(H),silent = T))
if ( class(r_temp)=="try-error" )
{
is.error=T
break
}
if(max(abs(dist))<tol) break
}
if (is.error)
{
break
}
if (key==1)
{
next
}
AIC_temp=-2*out_quasi$partial_likelihood+2*p*K_set[i]
if ( AIC_temp < AIC_QN )
{
K=K_set[i]
AIC_QN=AIC_temp
}
}
constrain=-diff(diag(K*1),differences=1)
# vfit = coxph(Surv(time,delta) ~.,data=data_original,iter.max = 40)
# constant_beta=vfit$coef
# N=n_train
# bs8=matrix(Bspline,nrow = N)
bs8=bs(time,df=K,knots =quantile(time[delta==1],probs = seq(1:(K-4))/(K-3)),intercept=T,degree = 3)
is.error=F
###quasi rank 2
quasi_time=proc.time()
theta_quasi=matrix(rep(constant_beta, K), nrow=p, byrow=FALSE)
partial_likelihood_quasi=NULL
key=0
repeat{
key=key+1
if (key==1){
out_quasi=ddloglik_schoenfeld(n=N,delta,z=z,beta=constant_beta,B_spline=bs8, knot=K)
H=out_quasi$GVG
g_pre=-matrix(out_quasi$GR_test,ncol=1)
d_pre=matrix(t(theta_quasi), ncol=1)
dist=matrix(solve(H)%*%g_pre, nrow=p, byrow=TRUE)
theta_quasi=theta_quasi-dist
out_quasi=ddloglik_schoenfeld_bs_t_quasi_L1(n=N,delta=delta,z=z,B_spline=bs8,  theta=theta_quasi,p,K)
g=matrix(out_quasi$L1,ncol=1)-g_pre
d=matrix(t(theta_quasi), ncol=1)-d_pre
b=as.vector(1/(t(g)%*%d))
c=as.vector(-1/(t(d)%*%H%*%d))
H=H+b*g%*%t(g)+c*H%*%d%*%t(d)%*%H
g_pre=matrix(out_quasi$L1,ncol=1)
d_pre=matrix(t(theta_quasi), ncol=1)
}
if (key>1){
dist=matrix(solve(H)%*%matrix(out_quasi$L1,ncol=1), nrow=p, byrow=TRUE)
theta_quasi=theta_quasi-dist
out_quasi=ddloglik_schoenfeld_bs_t_quasi_L1(n=N,delta=delta,z=z,B_spline=bs8,  theta=theta_quasi,p,K)
g=matrix(out_quasi$L1,ncol=1)-g_pre
d=matrix(t(theta_quasi), ncol=1)-d_pre
g_pre=matrix(out_quasi$L1,ncol=1)
d_pre=matrix(t(theta_quasi), ncol=1)
b=as.vector(1/(t(g)%*%d))
c=as.vector(-1/(t(d)%*%H%*%d))
H=H+b*g%*%t(g)+c*H%*%d%*%t(d)%*%H
}
if ( is.na(max(abs(dist))<tol) )
{
is.error=T
break
}
r_temp=suppressWarnings(try(solve(H),silent = T))
if ( class(r_temp)=="try-error" )
{
is.error=T
break
}
if(max(abs(dist))<tol) break
}
if (is.error)
{
cat("QN error!","\n")
return(NULL)
}
# quasi_key=c(quasi_key,key)
quasi_time=proc.time()-quasi_time
# quasi_time_all=c(quasi_time_all,quasi_time[3])
# beta.quasi.all=rbind(beta.quasi.all, theta_quasi)
# time_all=rbind(time_all,time)
test_quasi=rep(0,p)
j=0
repeat{
j=j+1
theta_quasi_j= theta_quasi[j,]
r_NT=suppressWarnings(try(solve(H),silent = T))
if (class(r_NT)=="try-error")
{
is.error=T
break
}
L2=solve(H)[((j-1)*K+1):((j-1)*K+K),((j-1)*K+1):((j-1)*K+K)]
test_contrast=t(constrain%*%theta_quasi_j)%*%solve(constrain%*%L2%*%t(constrain))%*%(constrain%*%theta_quasi_j)
test_quasi[j]=1-pchisq(test_contrast, (K-1))
if(j==p) break
}
if (is.error)
{
cat("QN error!","\n")
return(NULL)
}
# test_quasi_all=rbind(test_quasi_all, test_quasi)
independent=which(test_quasi>0.05)
if (length(independent)==0){
# beta.quasi.constrain.all=rbind(beta.quasi.constrain.all, theta_quasi)
} else {
constrain_matrix=NULL
for (j in 1:p){
if (j %in% independent) {
constrain_temp=matrix(0,nrow=K-1,ncol=p*K)
constrain_temp[, ((j-1)*K+1):(j*K)]=-diff(diag(K*1),differences=1)
constrain_matrix=rbind(constrain_matrix,constrain_temp)
}
}
###quasi rank 2 with constrain
theta_quasi=matrix(rep(constant_beta, K), nrow=p, byrow=FALSE)
partial_likelihood_quasi=NULL
key=0
repeat{
key=key+1
if (key==1){
out_quasi=ddloglik_schoenfeld(n=N,delta,z=z,beta=constant_beta,B_spline=bs8, knot=K)
H=out_quasi$GVG
g_pre=-matrix(out_quasi$GR_test,ncol=1)
d_pre=matrix(t(theta_quasi), ncol=1)
dist=matrix((solve(H)-solve(H)%*%t(constrain_matrix)%*%solve(constrain_matrix%*%solve(H)%*%t(constrain_matrix))%*%constrain_matrix%*%solve(H))%*%g_pre, nrow=p, byrow=TRUE)
theta_quasi=theta_quasi-dist
out_quasi=ddloglik_schoenfeld_bs_t_quasi_L1(n=N,delta=delta,z=z,B_spline=bs8,  theta=theta_quasi,p,K)
g=matrix(out_quasi$L1,ncol=1)-g_pre
d=matrix(t(theta_quasi), ncol=1)-d_pre
b=as.vector(1/(t(g)%*%d))
c=as.vector(-1/(t(d)%*%H%*%d))
H=H+b*g%*%t(g)+c*H%*%d%*%t(d)%*%H
g_pre=matrix(out_quasi$L1,ncol=1)
d_pre=matrix(t(theta_quasi), ncol=1)
}
if (key>1){
dist=matrix((solve(H)-solve(H)%*%t(constrain_matrix)%*%solve(constrain_matrix%*%solve(H)%*%t(constrain_matrix))%*%constrain_matrix%*%solve(H))%*%out_quasi$L1, nrow=p, byrow=TRUE)
theta_quasi=theta_quasi-dist
out_quasi=ddloglik_schoenfeld_bs_t_quasi_L1(n=N,delta=delta,z=z,B_spline=bs8,  theta=theta_quasi,p,K)
g=matrix(out_quasi$L1,ncol=1)-g_pre
d=matrix(t(theta_quasi), ncol=1)-d_pre
g_pre=matrix(out_quasi$L1,ncol=1)
d_pre=matrix(t(theta_quasi), ncol=1)
b=as.vector(1/(t(g)%*%d))
c=as.vector(-1/(t(d)%*%H%*%d))
H=H+b*g%*%t(g)+c*H%*%d%*%t(d)%*%H
}
if (is.na(max(abs(dist))<tol))
{
is.error=T
break
}
r_temp=suppressWarnings(try(solve(H),silent = T))
if ( class(r_temp)=="try-error" )
{
is.error=T
break
}
if(max(abs(dist))<tol) break
}
# beta.quasi.constrain.all=rbind(beta.quasi.constrain.all, theta_quasi)
}
if (is.error)
{
cat("QN error!","\n")
return(NULL)
}
location_t_star=vapply(1:length(t_star),function(x) sum(t_star[x]>=time),FUN.VALUE = as.numeric(1) )
# BScore_train_MA=0
# BScore_train_NT=0
# BScore_train_RF=0
# BScore_train_XG=0
# BScore_train_boost=0
# BScore_train_bag=0
# BScore_train_Li=0
# for (i in 1:n_train)
# {
#   W_i=vapply(1:length(t_star),FUN =function(x) w_t_i_test(t_star[x],i,time,delta,G),FUN.VALUE = as.numeric(1))
#   I_i=t_star<time[i]
#
#   S_i=vapply(1:p
#              ,FUN = function(x)   c(rep(1,sum(location_t_star==0)),Breslow_S(n_train,delta,z,Bspline,x,submodel_all[[x]][["coefficients"]][1:(p-1)],submodel_all[[x]][["coefficients"]][p:(p+K-1)],z[i,])[location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
#              ,FUN.VALUE = as.double(1:length(t_star)))
#   S_i_hat=S_i%*%w_best
#   S_i_quasiNewton<-c(rep(1,sum(location_t_star==0)),quasiNewton_S(n_train,delta,z, bs8, theta_quasi,z[i,])[location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
#   S_i_RF<-c(rep(1,sum(location_f_t_star==0)),S_train_RF[,i][location_f_t_star[ (sum(location_f_t_star==0)+1):length(t_star) ]])
#   S_i_XG<-c(rep(1,sum(location_t_star==0)),S_train_XG[,i][location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
#   S_i_boost<-c(rep(1,sum(location_t_star==0)),S_train_boost[,i][location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
#   location_bag1_i=vapply(1:length(t_star),function(x) sum(t_star[x]>=bag_train_temp[[i]][["time"]]),FUN.VALUE = as.numeric(1) )
#   S_i_bag<-c(rep(1,sum(location_bag1_i==0)),bag_train_temp[[i]][["surv"]][location_bag1_i[ (sum(location_bag1_i==0)+1):length(t_star) ]])
#   S_i_Li<-c(rep(1,sum(location_t_star==0)),DoubleLike_S(n_train,delta,z, Bspline,w_Li,theta,z[i,],beta_add0_Li)[location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
#
#   BScore_train_MA=BScore_train_MA+(I_i-S_i_hat)^2*W_i
#   BScore_train_NT=BScore_train_NT+(I_i-S_i_quasiNewton)^2*W_i
#   BScore_train_RF=BScore_train_RF+(I_i-S_i_RF)^2*W_i
#   BScore_train_XG=BScore_train_XG+(I_i-S_i_XG)^2*W_i
#   BScore_train_boost=BScore_train_boost+(I_i-S_i_boost)^2*W_i
#   BScore_train_bag=BScore_train_bag+(I_i-S_i_bag)^2*W_i
#   BScore_train_Li=BScore_train_Li+(I_i-S_i_Li)^2*W_i
# }
# BScore_train_MA=BScore_train_MA/n_train
# BScore_train_NT=BScore_train_NT/n_train
# BScore_train_RF=BScore_train_RF/n_train
# BScore_train_XG=BScore_train_XG/n_train
# BScore_train_boost=BScore_train_boost/n_train
# BScore_train_bag=BScore_train_bag/n_train
# BScore_train_Li=BScore_train_Li/n_train
#
#
#
#
# S_MA_train=vapply(1:n_train,function(i) vapply(1:p,FUN = function(x)   Breslow_S(n_train,delta,z,Bspline,x,submodel_all[[x]][["coefficients"]][1:(p-1)],submodel_all[[x]][["coefficients"]][p:(p+K-1)],z[i,]),FUN.VALUE = as.double(1:n_train))%*%w_best,as.double(1:n_train))
# S_NT_train=vapply(1:n_train,function(i) quasiNewton_S(n_train,delta,z, bs8, theta_quasi,z[i,]) , as.double(1:n_train))
# S_Li_train=vapply(1:n_train,function(i) DoubleLike_S(n_train,delta,z, Bspline,w_Li,theta,z[i,],beta_add0_Li) , as.double(1:n_train))
#
# Cin_MA_numerator=0
# Cin_NT_numerator=0
# Cin_RF_numerator=0
# Cin_XG_numerator=0
# Cin_boost_numerator=0
# Cin_bag_numerator=0
# Cin_Li_numerator=0
# Cin_denominator=0
# for (i in 1:(n_train-1))
# {
#   if (delta[i]==0)
#     next
#   location_bag1_i=vapply(1:n_train,function(x) sum(time[x]>=bag_train_temp[[i]][["time"]]),FUN.VALUE = as.numeric(1) )
#   for (j in (i+1):n_train)
#   {
#     Cin_MA_numerator=Cin_MA_numerator+(time[i]<time[j])*delta[i]*( S_MA_train[i,i] < S_MA_train[i,j] )
#     Cin_NT_numerator=Cin_NT_numerator+(time[i]<time[j])*delta[i]*( S_NT_train[i,i] < S_NT_train[i,j] )
#     Cin_RF_numerator=Cin_RF_numerator+(time[i]<time[j])*delta[i]*( c(rep(1,sum(location_f1==0)),S_train_RF[,i][location_f1[ (sum(location_f1==0)+1):n_train ]])[i] < c(rep(1,sum(location_f1==0)),S_train_RF[,j][location_f1[ (sum(location_f1==0)+1):n_train ]])[i]   )
#     Cin_XG_numerator=Cin_XG_numerator+(time[i]<time[j])*delta[i]*( (S_train_XG[,i])[i] < (S_train_XG[,j])[i] )
#     Cin_boost_numerator=Cin_boost_numerator+(time[i]<time[j])*delta[i]*( (S_train_boost[,i])[i] < (S_train_boost[,j])[i] )
#     location_bag1_j=vapply(1:n_train,function(x) sum(time[x]>=bag_train_temp[[j]][["time"]]),FUN.VALUE = as.numeric(1) )
#     Cin_bag_numerator=Cin_bag_numerator+(time[i]<time[j])*delta[i]*( c(rep(1,sum(location_bag1_i==0)),bag_train_temp[[i]][["surv"]][location_bag1_i[ (sum(location_bag1_i==0)+1):n_train ]])[i]
#                                                                      < c(rep(1,sum(location_bag1_j==0)),bag_train_temp[[j]][["surv"]][location_bag1_j[ (sum(location_bag1_j==0)+1):n_train ]])[i] )
#     Cin_Li_numerator=Cin_Li_numerator+(time[i]<time[j])*delta[i]*( S_Li_train[i,i] < S_Li_train[i,j] )
#     Cin_denominator=Cin_denominator+(time[i]<time[j])*delta[i]
#   }
# }
# Cindex_MA_train=Cin_MA_numerator/Cin_denominator
# Cindex_NT_train=Cin_NT_numerator/Cin_denominator
# Cindex_RF_train=Cin_RF_numerator/Cin_denominator
# Cindex_XG_train=Cin_XG_numerator/Cin_denominator
# Cindex_boost_train=Cin_boost_numerator/Cin_denominator
# Cindex_bag_train=Cin_bag_numerator/Cin_denominator
# Cindex_Li_train=Cin_Li_numerator/Cin_denominator
G_test=matrix(rep(model_c$surv,n_test),byrow = F,ncol = n_test)
if (n_train-nrow(G_test)!=0)
G_test=rbind(G_test,matrix(rep(G_test[nrow(G_test),],n_train-nrow(G_test)),nrow = n_train-nrow(G_test),byrow = T))
location=vapply(1:n_test,function(x) sum(time_test[x]>=time),FUN.VALUE = as.numeric(1) )
BScore_test_MA=0
BScore_test_NT=0
BScore_test_RF=0
BScore_test_XG=0
BScore_test_boost=0
BScore_test_bag=0
BScore_test_Li=0
for (i in 1:n_test)
{
W_i=vapply(1:length(t_star),FUN =function(x) w_t_i_test(t_star[x],i,time_test,delta_test,G_test),FUN.VALUE = as.numeric(1))
I_i=t_star<time_test[i]
S_i=vapply(1:p
,FUN = function(x)   c(rep(1,sum(location_t_star==0)),Breslow_S(n_train,delta,z,Bspline,x,submodel_all[[x]][["coefficients"]][1:(p-1)],submodel_all[[x]][["coefficients"]][p:(p+K_MA-1)],z_test[i,])[location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
,FUN.VALUE = as.double(1:length(t_star)))
S_i_hat=S_i%*%w_best
S_i_quasiNewton<-c(rep(1,sum(location_t_star==0)),quasiNewton_S(n_train,delta,z, bs8, theta_quasi,z_test[i,])[location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
S_i_RF<-c(rep(1,sum(location_f_t_star==0)),S_test_RF[,i][location_f_t_star[ (sum(location_f_t_star==0)+1):length(t_star) ]])
S_i_XG<-c(rep(1,sum(location_t_star==0)),S_test_XG[,i][location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
S_i_boost<-c(rep(1,sum(location_t_star==0)),S_test_boost[,i][location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
location_bag2_i=vapply(1:length(t_star),function(x) sum(t_star[x]>=bag_test_temp[[i]][["time"]]),FUN.VALUE = as.numeric(1) )
S_i_bag<-c(rep(1,sum(location_bag2_i==0)),bag_test_temp[[i]][["surv"]][location_bag2_i[ (sum(location_bag2_i==0)+1):length(t_star) ]])
S_i_Li<-c(rep(1,sum(location_t_star==0)),DoubleLike_S(n_train,delta,z, Bspline,w_Li,theta,z_test[i,],beta_add0_Li)[location_t_star[ (sum(location_t_star==0)+1):length(t_star) ]])
BScore_test_MA=BScore_test_MA+(I_i-S_i_hat)^2*W_i
BScore_test_NT=BScore_test_NT+(I_i-S_i_quasiNewton)^2*W_i
BScore_test_RF=BScore_test_RF+(I_i-S_i_RF)^2*W_i
BScore_test_XG=BScore_test_XG+(I_i-S_i_XG)^2*W_i
BScore_test_boost=BScore_test_boost+(I_i-S_i_boost)^2*W_i
BScore_test_bag=BScore_test_bag+(I_i-S_i_bag)^2*W_i
BScore_test_Li=BScore_test_Li+(I_i-S_i_Li)^2*W_i
}
BScore_test_MA=BScore_test_MA/n_test
BScore_test_NT=BScore_test_NT/n_test
BScore_test_RF=BScore_test_RF/n_test
BScore_test_XG=BScore_test_XG/n_test
BScore_test_boost=BScore_test_boost/n_test
BScore_test_bag=BScore_test_bag/n_test
BScore_test_Li=BScore_test_Li/n_test
S_MA_test=vapply(1:n_test,function(i) vapply(1:p,FUN = function(x)   c(rep(1,sum(location==0)),Breslow_S(n_train,delta,z,Bspline,x,submodel_all[[x]][["coefficients"]][1:(p-1)],submodel_all[[x]][["coefficients"]][p:(p+K_MA-1)],z_test[i,])[location[ (sum(location==0)+1):n_test ]]),FUN.VALUE = as.double(1:n_test))%*%w_best,as.double(1:n_test))
S_NT_test=vapply(1:n_test, function(i) c(rep(1,sum(location==0)),quasiNewton_S(n_train,delta,z, bs8, theta_quasi,z_test[i,])[location[ (sum(location==0)+1):n_test ]]), as.double(1:n_test))
S_Li_test=vapply(1:n_test, function(i) c(rep(1,sum(location==0)),DoubleLike_S(n_train,delta,z, Bspline,w_Li,theta,z_test[i,],beta_add0_Li)[location[ (sum(location==0)+1):n_test ]]), as.double(1:n_test))
Cin_MA_numerator=0
Cin_NT_numerator=0
Cin_RF_numerator=0
Cin_XG_numerator=0
Cin_boost_numerator=0
Cin_bag_numerator=0
Cin_Li_numerator=0
Cin_denominator=0
for (i in 1:(n_test-1))
{
if (delta_test[i]==0)
next
location_bag2_i=vapply(1:n_test,function(x) sum(time_test[x]>=bag_test_temp[[i]][["time"]]),FUN.VALUE = as.numeric(1) )
for (j in (i+1):n_test)
{
Cin_MA_numerator=Cin_MA_numerator+(time_test[i]<time_test[j])*delta_test[i]*( S_MA_test[i,i] < S_MA_test[i,j] )
Cin_NT_numerator=Cin_NT_numerator+(time_test[i]<time_test[j])*delta_test[i]*( S_NT_test[i,i] < S_NT_test[i,j] )
Cin_RF_numerator=Cin_RF_numerator+(time_test[i]<time_test[j])*delta_test[i]*( c(rep(1,sum(location_f2==0)),S_test_RF[,i][location_f2[ (sum(location_f2==0)+1):n_test ]])[i]
< c(rep(1,sum(location_f2==0)),S_test_RF[,j][location_f2[ (sum(location_f2==0)+1):n_test ]])[i]   )
Cin_XG_numerator=Cin_XG_numerator+(time_test[i]<time_test[j])*delta_test[i]*( c(rep(1,sum(location==0)),S_test_XG[,i][location[ (sum(location==0)+1):n_test ]])[i]
< c(rep(1,sum(location==0)),S_test_XG[,j][location[ (sum(location==0)+1):n_test ]])[i] )
Cin_boost_numerator=Cin_boost_numerator+(time_test[i]<time_test[j])*delta_test[i]*( c(rep(1,sum(location==0)),S_test_boost[,i][location[ (sum(location==0)+1):n_test ]])[i]
< c(rep(1,sum(location==0)),S_test_boost[,j][location[ (sum(location==0)+1):n_test ]])[i] )
location_bag2_j=vapply(1:n_test,function(x) sum(time_test[x]>=bag_test_temp[[j]][["time"]]),FUN.VALUE = as.numeric(1) )
Cin_bag_numerator=Cin_bag_numerator+(time_test[i]<time_test[j])*delta_test[i]*( c(rep(1,sum(location_bag2_i==0)),bag_test_temp[[i]][["surv"]][location_bag2_i[ (sum(location_bag2_i==0)+1):n_test ]])[i]
< c(rep(1,sum(location_bag2_j==0)),bag_test_temp[[j]][["surv"]][location_bag2_j[ (sum(location_bag2_j==0)+1):n_test ]])[i] )
Cin_Li_numerator=Cin_Li_numerator+(time_test[i]<time_test[j])*delta_test[i]*( S_Li_test[i,i] < S_Li_test[i,j] )
Cin_denominator=Cin_denominator+(time_test[i]<time_test[j])*delta_test[i]
}
}
Cindex_MA_test=Cin_MA_numerator/Cin_denominator
Cindex_NT_test=Cin_NT_numerator/Cin_denominator
Cindex_RF_test=Cin_RF_numerator/Cin_denominator
Cindex_XG_test=Cin_XG_numerator/Cin_denominator
Cindex_boost_test=Cin_boost_numerator/Cin_denominator
Cindex_bag_test=Cin_bag_numerator/Cin_denominator
Cindex_Li_test=Cin_Li_numerator/Cin_denominator
# if ( sum(is.na( c(BScore_train_MA,BScore_train_NT,BScore_train_RF,BScore_train_XG,BScore_train_boost,BScore_train_bag,BScore_train_Li) ))
#      +sum(is.na( c(Cindex_MA_train,Cindex_NT_train,Cindex_RF_train,Cindex_XG_train,Cindex_boost_train,Cindex_bag_train,Cindex_Li_train) ))
#      +sum(is.na( c(BScore_test_MA,BScore_test_NT,BScore_test_RF,BScore_test_XG,BScore_test_boost,BScore_test_bag,BScore_test_Li) ))
#      +sum(is.na( c(Cindex_MA_test,Cindex_NT_test,Cindex_RF_test,Cindex_XG_test,Cindex_boost_test,Cindex_bag_test,Cindex_Li_test) )) >0 )
if ( sum(is.na( c(BScore_test_MA,BScore_test_NT,BScore_test_RF,BScore_test_XG,BScore_test_boost,BScore_test_bag,BScore_test_Li) ))
+sum(is.na( c(Cindex_MA_test,Cindex_NT_test,Cindex_RF_test,Cindex_XG_test,Cindex_boost_test,Cindex_bag_test,Cindex_Li_test) )) >0 )
{
return(NULL)
}
temp=list(BScore_test=list(BScore_test_MA,BScore_test_NT,BScore_test_RF,BScore_test_XG,BScore_test_boost,BScore_test_bag,BScore_test_Li),
Cindex_test=list(Cindex_MA_test,Cindex_NT_test,Cindex_RF_test,Cindex_XG_test,Cindex_boost_test,Cindex_bag_test,Cindex_Li_test),
data_all=data_r
)
View(temp)
View(temp)
library(MAtimeCOX)
library(MAtimeCOX)
?Breslow.S.m
rm(list = ls())
library(survival)
library(timereg)
library(splines)
library(quadprog)
# Extract a train data set
data(sTRACE)
sTRACE=na.omit(sTRACE)
data=sTRACE[sTRACE$status==0 | sTRACE$status==9,c(2,4,5,6,7,9,8,3)]
data$status=data$status/9
# Estimate the candidate models and their weights
submodels=MAtdcCOX(data,c(5:8),test.plot=F,compute.S=T)
n=submodels$n
delta=submodels$delta.order
z=submodels$z.order
Bspline=submodels$Bspline
submodel_all=submodels$candidate_models
p=submodels$p
K=submodels$K_n
# For the first candidate model, estimate the conditional survival function given covariate vector "z[1,]" by the Breslow type method
Breslow_S_temp=Breslow.S.m(n,delta,z,Bspline,1,submodel_all[[1]][["coefficients"]][1:(p-1)],submodel_all[[1]][["coefficients"]][p:(p+K-1)],z[1,])
library(MAtimeCOX)
?Breslow.S.m
rm(list = ls())
library(survival)
library(timereg)
library(splines)
library(quadprog)
# Extract a train data set
data(sTRACE)
sTRACE=na.omit(sTRACE)
data=sTRACE[sTRACE$status==0 | sTRACE$status==9,c(2,4,5,6,7,9,8,3)]
data$status=data$status/9
# Estimate the candidate models and their weights
submodels=MAtdcCOX(data,c(5:8),test.plot=F,compute.S=T)
n=submodels$n
delta=submodels$delta.order
z=submodels$z.order
Bspline=submodels$Bspline
submodel_all=submodels$candidate_models
p=submodels$p
K=submodels$K_n
# For the first candidate model, estimate the conditional survival function given covariate vector "z[1,]" by the Breslow type method
Breslow_S_temp=Breslow.S.m(n,delta,z,Bspline,1,submodel_all[[1]][["coefficients"]][1:(p-1)],submodel_all[[1]][["coefficients"]][p:(p+K-1)],z[1,])
?data.expand
rm(list = ls())
library(timereg)
library(splines)
# Extract a train data set
data(sTRACE)
sTRACE=na.omit(sTRACE)
data=sTRACE[sTRACE$status==0 | sTRACE$status==9,c(2,4,5,6,7,9,8,3)]
data$status=data$status/9
n=nrow(data)
p=ncol(data)-2
K=9
z=as.matrix(data[,1:p])
time=data[,ncol(data)-1]
delta=data[,ncol(data)]
delta=delta[order(time)]
z=z[order(time),]
time=time[order(time)]
Bspline=bs(time,df=K,knots =quantile(time[delta==1],probs = seq(1:(K-4))/(K-3)),intercept=T,degree = 3)
# Expand the original data set in the counting-process style
data_new=data.expand(delta, time, z, Bspline,K)
View(data_new)
rm(list = ls())
library(survival)
library(timereg)
library(splines)
library(quadprog)
# Extract a train data set
data(sTRACE)
sTRACE=na.omit(sTRACE)
data=sTRACE[sTRACE$status==0 | sTRACE$status==9,c(2,4,5,6,7,9,8,3)]
data$status=data$status/9
# Estimate the candidate models and their weights based on the train data set
submodels=MAtdcCOX(data,c(5:8),test.plot=F,compute.S=T)
# Predict the conditional survival functions at time points "{1,2,3,4,5}" given the covariate matrix
results_pre=MApredict(submodels,submodels$z.order[1:3,],c(1:5))
View(results_pre)
View(results_pre)
View(results_pre[["S_MA_test"]])
results_pre[["t_star.order"]]
results_pre[["S_MA_t_star"]]\
results_pre[["S_MA_t_star"]]
results_pre[["t_star.order"]]
results_pre[["time.order"]]
?w.t.i.G
rm(list = ls())
library(survival)
# Create a simple data set
set.seed(1)
n=100
time=rexp(n,0.5)
delta=rbinom(n,1,0.4)
delta=delta[order(time)]
time=time[order(time)]
data=data.frame(time,delta)
model_c=survfit(Surv(time,1-delta)~1,data = data)
# Estimate the survival function of censoring time
G=matrix(rep(model_c$surv,n),byrow = F,ncol = n)
# Compute the Inverse of Probability of Censoring Weighting for the first subject at time point "time[1]"
weight_temp=w.t.i.G(time[1],1,time,delta,G)
rm(list = ls())
library(survival)
library(timereg)
library(splines)
library(quadprog)
# Extract a train data set
data(sTRACE)
sTRACE=na.omit(sTRACE)
data=sTRACE[sTRACE$status==0 | sTRACE$status==9,c(2,4,5,6,7,9,8,3)]
data$status=data$status/9
# Estimate the candidate models and their weights
submodels=MAtdcCOX(data,c(5:8),test.plot=F,compute.S=T)
View(submodels)
submodels[["test"]][["table"]]
submodels[["MA_weights"]]
submodels[["test"]]
library(MAtimeCOX)
